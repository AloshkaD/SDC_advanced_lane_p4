{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read in an image using matplotlib.image.imread() you will get an RGB image, but if you read it in using OpenCV cv2.imread() this will give you a BGR image. \n",
    "\n",
    "hls = cv2.cvtColor(im, cv2.COLOR_RGB2HLS) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "import glob\n",
    "import math\n",
    "from skimage.feature import corner_harris,corner_peaks\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gaussian_noise(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255   \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def inverse_region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255   \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_or(mask, img)\n",
    "    inverse_masked_image = cv2.bitwise_not(masked_image , img)\n",
    "     \n",
    "    #return masked_image\n",
    "    return inverse_masked_image\n",
    "\n",
    "def transform(img):\n",
    "    imshape = img.shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #src=np.float32([[160,imshape[0]],[imshape[1]/2-60, imshape[0]/2+90],[imshape[1]/2+100, imshape[0]/2+90], [imshape[1]-20,imshape[0]]])\n",
    "    #dst=np.float32([[(240,imshape[0]),(240, 0),(imshape[1]-130, 0), (imshape[1]-130,imshape[0])]])\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                     [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    wraped =  cv2.warpPerspective(img,M,img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return  Minv, wraped\n",
    "\n",
    "# Read in an image and grayscale it\n",
    " \n",
    "## return sobel threshold\n",
    "def abs_sobel_thresh(img, orient, sobel_kernel, thresh):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    #binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "## return mag_direction\n",
    "\n",
    "def mag_thresh(img, sobel_kernel, mag_thresh):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "## return the gradient\n",
    "\n",
    "def dir_threshold(img, sobel_kernel, thresh=(0, np.pi/2)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx=np.absolute(sobelx)\n",
    "    abs_sobely=np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(dir_grad)\n",
    "    binary_output[(dir_grad >= thresh[0]) & (dir_grad <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "\n",
    "class Left:\n",
    "    def __init__(self):\n",
    "        # Was the line found in the previous frame?\n",
    "        self.found = False\n",
    "        \n",
    "        # Remember x and y values of lanes in previous frame\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "        # Store recent x intercepts for averaging across frames\n",
    "        self.x_int = []\n",
    "        self.top = []\n",
    "        \n",
    "        # Remember previous x intercept to compare against current one\n",
    "        self.lastx_int = None\n",
    "        self.last_top = None\n",
    "        \n",
    "        # Remember radius of curvature\n",
    "        self.radius = None\n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = []\n",
    "        self.fit1 = []\n",
    "        self.fit2 = []\n",
    "        self.fitx = None\n",
    "        self.pts = []\n",
    "        \n",
    "        # Count the number of frames\n",
    "        self.count = 0\n",
    "\n",
    "        \n",
    "class Right:\n",
    "    def __init__(self):\n",
    "        # Was the line found in the previous frame?\n",
    "        self.found = False\n",
    "        \n",
    "        # Remember x and y values of lanes in previous frame\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "        # Store recent x intercepts for averaging across frames\n",
    "        self.x_int = []\n",
    "        self.top = []\n",
    "        \n",
    "        # Remember previous x intercept to compare against current one\n",
    "        self.lastx_int = None\n",
    "        self.last_top = None\n",
    "        \n",
    "        # Remember radius of curvature\n",
    "        self.radius = None\n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = []\n",
    "        self.fit1 = []\n",
    "        self.fit2 = []\n",
    "        self.fitx = None\n",
    "        self.pts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform camera calibration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        \n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Implement calibration on the images that will be used\n",
    "\n",
    "\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    #cv2.imwrite('test_images/test6.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "#dist_pickle = {}\n",
    "#dist_pickle[\"mtx\"] = mtx\n",
    "#dist_pickle[\"dist\"] = dist\n",
    "#pickle.dump( dist_pickle, open( \"calibration_wide/wide_dist_pickle.p\", \"wb\" ) )\n",
    "\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize undistortion\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "#ax1.imshow(img)\n",
    "#ax1.set_title('Original Image', fontsize=30)\n",
    "#ax2.imshow(dst)\n",
    "#ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_vid(image):\n",
    " \n",
    "\n",
    "    # Test undistortion on an image\n",
    "    #img = cv2.imread('test_images/Distorted/test6.jpg')\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "#img = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx) \n",
    "    image = undist\n",
    "#Read in the image\n",
    "#image = mpimg.imread('test_images/test6.jpg')\n",
    "#Blur the image\n",
    "    blur_kernel_size = 1\n",
    "    image = gaussian_noise(image, blur_kernel_size)\n",
    "\n",
    "#Define a mask but only implement it after edge detection dot not be detected\n",
    "    imshape = image.shape\n",
    "        #vertices = np.array([[(80,imshape[0]),(400, 330), (580, 330), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    vertices = np.array([[(160,imshape[0]),(imshape[1]/2-70, imshape[0]/2+90),\n",
    "                      (imshape[1]/2+130, imshape[0]/2+90), (imshape[1]-20,imshape[0])]], dtype=np.int32)\n",
    "    #vertices = np.array([[(160,imshape[0]),(imshape[1]/2-60, imshape[0]/2+90),\n",
    "                      #(imshape[1]/2+100, imshape[0]/2+90), (imshape[1]-20,imshape[0])]], dtype=np.int32)\n",
    "#image = region_of_interest(image, vertices)\n",
    "    vertices_small = np.array([[(300,imshape[0]),(imshape[1]/2-110, imshape[0]/2+200),\n",
    "                      (imshape[1]/2+200, imshape[0]/2+200), (imshape[1]-150,imshape[0])]], dtype=np.int32) \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    " \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "    #binary = np.zeros_like(gray)\n",
    "    #binary[(gray > thresh[0]) & (gray <= thresh[1])] = 1\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(image)\n",
    "#ax1.set_title('Original Image', fontsize=50)\n",
    "#ax2.imshow(binary, cmap='gray')\n",
    "#ax2.set_title('Thresholded Gradient', fontsize=50)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "# Splitting RGB Channels\n",
    "    #R = image[:,:,0]\n",
    "    #G = image[:,:,1]\n",
    "    B = image[:,:,2]\n",
    "    thresh = (220, 255)\n",
    "#gray_ = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #binary_R = np.zeros_like(R)\n",
    "    #binary_R[(R > thresh[0]) & (R <= thresh[1])] = 1\n",
    "    #binary_R= region_of_interest(binary_R, vertices)\n",
    "    #binary_R= inverse_region_of_interest(binary_R, vertices_small)\n",
    "    #binary_R= inverse_region_of_interest(binary_R, vertices_small)\n",
    "    \n",
    "    \"\"\"\n",
    "    binary_G = np.zeros_like(G)\n",
    "    binary_G[(G > thresh[0]) & (G <= thresh[1])] = 1\n",
    "    binary_G= region_of_interest(binary_G, vertices)\n",
    "    binary_G= inverse_region_of_interest(binary_G, vertices_small)\n",
    "    binary_G= inverse_region_of_interest(binary_G, vertices_small)\n",
    "    \"\"\"\n",
    "    binary_B = np.zeros_like(B)\n",
    "    binary_B[(B > thresh[0]) & (B <= thresh[1])] = 1\n",
    "    binary_B= region_of_interest(binary_B, vertices)\n",
    "    binary_B= inverse_region_of_interest(binary_B, vertices_small)\n",
    "    binary_B= inverse_region_of_interest(binary_B, vertices_small)\n",
    "\n",
    "\n",
    "    # Splitting HSV Channels\n",
    "    LUV = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "\n",
    "    L = LUV[:,:,0]\n",
    "    U = LUV[:,:,1]\n",
    "    V = LUV[:,:,2]\n",
    "    thresh = (215, 255)\n",
    "    #gray_ = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    binary_L = np.zeros_like(L)\n",
    "    binary_L[(L > thresh[0]) & (L <= thresh[1])] = 1\n",
    "    binary_L= region_of_interest(binary_L, vertices)\n",
    "    #binary_L= inverse_region_of_interest(binary_L, vertices_small)\n",
    "    #binary_L= inverse_region_of_interest(binary_L, vertices_small)\n",
    "\n",
    "\n",
    "    binary_U = np.zeros_like(U)\n",
    "    binary_U[(U > thresh[0]) & (U <= thresh[1])] = 1\n",
    "    binary_U= region_of_interest(binary_U, vertices)\n",
    "    #binary_U= inverse_region_of_interest(binary_U, vertices_small)\n",
    "    #binary_U= inverse_region_of_interest(binary_U, vertices_small)\n",
    "\n",
    "\n",
    "    binary_V = np.zeros_like(V)\n",
    "    binary_V[(V > thresh[0]) & (V <= thresh[1])] = 1\n",
    "    binary_V= region_of_interest(binary_V, vertices)\n",
    "    binary_V= inverse_region_of_interest(binary_V, vertices_small)\n",
    "    binary_V= inverse_region_of_interest(binary_V, vertices_small)\n",
    "    \n",
    "    \n",
    "    HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    H = HLS[:,:,0]\n",
    "    L = HLS[:,:,1]\n",
    "    S = HLS[:,:,2]\n",
    "    thresh = (215, 255)\n",
    "    #gray_ = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    binary_H = np.zeros_like(H)\n",
    "    binary_H[(H > thresh[0]) & (H <= thresh[1])] = 1\n",
    "    binary_H= region_of_interest(binary_H, vertices)\n",
    "    #binary_L= inverse_region_of_interest(binary_L, vertices_small)\n",
    "    #binary_L= inverse_region_of_interest(binary_L, vertices_small)\n",
    "\n",
    "\n",
    "    binary_L = np.zeros_like(L)\n",
    "    binary_L[(L > thresh[0]) & (L <= thresh[1])] = 1\n",
    "    binary_L= region_of_interest(binary_L, vertices)\n",
    "    #binary_U= inverse_region_of_interest(binary_U, vertices_small)\n",
    "    #binary_U= inverse_region_of_interest(binary_U, vertices_small)\n",
    "\n",
    "\n",
    "    binary_V = np.zeros_like(V)\n",
    "    binary_V[(V > thresh[0]) & (V <= thresh[1])] = 1\n",
    "    binary_V= region_of_interest(binary_V, vertices)\n",
    "    binary_V= inverse_region_of_interest(binary_V, vertices_small)\n",
    "    binary_V= inverse_region_of_interest(binary_V, vertices_small)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####\n",
    "    Lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "    L = Lab[:,:,0]\n",
    "    a = Lab[:,:,1]\n",
    "    b = Lab[:,:,2]\n",
    "    thresh = (140, 200)\n",
    "    #gray_ = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    binary_L = np.zeros_like(L)\n",
    "    binary_L[(L > thresh[0]) & (L <= thresh[1])] = 1\n",
    "    binary_L= region_of_interest(binary_L, vertices)\n",
    "    binary_L= inverse_region_of_interest(binary_L, vertices_small)\n",
    "    binary_L= inverse_region_of_interest(binary_L, vertices_small)\n",
    "\n",
    "\n",
    "    binary_a = np.zeros_like(a)\n",
    "    binary_a[(a > thresh[0]) & (a <= thresh[1])] = 1\n",
    "    binary_a= region_of_interest(binary_a, vertices)\n",
    "    binary_a= inverse_region_of_interest(binary_a, vertices_small)\n",
    "    binary_a= inverse_region_of_interest(binary_a, vertices_small)\n",
    "\n",
    "\n",
    "    binary_b = np.zeros_like(b)\n",
    "    binary_b[(b > thresh[0]) & (b <= thresh[1])] = 1\n",
    "    binary_b= region_of_interest(binary_b, vertices)\n",
    "    #binary_b= inverse_region_of_interest(binary_b, vertices_small)\n",
    "    #binary_b= inverse_region_of_interest(binary_b, vertices_small)    \n",
    "    ####\n",
    "    \n",
    "    \n",
    "    \n",
    "    ksize=3\n",
    "\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    gradx = region_of_interest(gradx, vertices)\n",
    "    gradx= inverse_region_of_interest(gradx, vertices_small)\n",
    "    gradx= inverse_region_of_interest(gradx, vertices_small)\n",
    "\n",
    "\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    grady = region_of_interest(grady, vertices)\n",
    "    grady= inverse_region_of_interest(grady, vertices_small)\n",
    "    grady= inverse_region_of_interest(grady, vertices_small)\n",
    "\n",
    "\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    mag_binary = region_of_interest(mag_binary, vertices)\n",
    "    mag_binary= inverse_region_of_interest(mag_binary, vertices_small)\n",
    "    mag_binary= inverse_region_of_interest(mag_binary, vertices_small)\n",
    "\n",
    "\n",
    "\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.3, 1.5)) \n",
    "    dir_binary = region_of_interest(dir_binary, vertices)\n",
    "    dir_binary= inverse_region_of_interest(dir_binary, vertices_small)\n",
    "    dir_binary= inverse_region_of_interest(dir_binary, vertices_small)\n",
    "\n",
    "#dir_binary = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "\n",
    "#Combine all combined binary and R channel\n",
    "\n",
    "    #combined_binary_R = np.zeros_like(combined )\n",
    "    #combined_binary_R[(binary_R== 1) | (combined == 1)] = 1\n",
    "\n",
    "#color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "#Combine all combined binary and S channel\n",
    "\n",
    "    #combined_binary_S = np.zeros_like(combined )\n",
    "    #combined_binary_S[(binary_S== 1) | (combined == 1)] = 1\n",
    "\n",
    "#Combine Sobel and R channel\n",
    "\n",
    "    #Sobel_binary_R = np.zeros_like(gradx)\n",
    "    #Sobel_binary_R[(binary_R== 1) | (gradx== 1)] = 1\n",
    "\n",
    "#Combine all combined binary and S channel\n",
    "\n",
    "    #Sobel_binary_S = np.zeros_like(gradx )\n",
    "    #Sobel_binary_S[(binary_S== 1) | (gradx == 1)] = 1\n",
    "    \n",
    "    combined_binary_test = np.zeros_like(binary_L)\n",
    "    combined_binary_test[(binary_B == 1) | (binary_b == 1)] = 1 \n",
    "    \n",
    "    Minv, warped_img= transform(combined_binary_test)\n",
    "    row_w,col_w=warped_img.shape\n",
    "\n",
    "    warped_img_left=warped_img[0:row_w,0:math.ceil(col_w/2)]\n",
    "    warped_img_right=warped_img[0:row_w,math.ceil(col_w/2):col_w]\n",
    "#def show_corners(corners_l, corners_r,image,title=None):\n",
    "    \"\"\"Display a list of corners overlapping an image\"\"\"\n",
    "    #fig = plt.figure()\n",
    "    #plt.imshow(image,cmap='gray')\n",
    "    \n",
    "    #y_corner_l = []\n",
    "    #x_corner_l = []\n",
    "    #y_corner_r = []\n",
    "    #x_corner_r = []\n",
    " \n",
    "    #corners_left = corner_peaks(corner_harris(warped_img_left),min_distance=2)\n",
    "    #corners_right = corner_peaks(corner_harris(warped_img_right),min_distance=2)\n",
    "    #y_corner_l,x_corner_l = zip(*corners_left)\n",
    "\n",
    "    #adjusted_corners_right= corners_right+[0,math.ceil(col_w/2)]\n",
    "                                      \n",
    "    #y_corner_r,x_corner_r = zip(*adjusted_corners_right)\n",
    "    #Measuring Curvature\n",
    "    #yvalus = warped_img.shape[0]\n",
    " # Generate some fake data to represent lane-line pixels\n",
    "    #yvals = np.linspace(0, 100, num=101)*(yvalus/100.0)  # to cover same y-range as image\n",
    "\n",
    "#leftx = np.array([200 + (elem**2)*4e-4 + np.random.randint(-50, high=51) \n",
    "                              #for idx, elem in enumerate(yvals)])\n",
    "#leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #leftx = np.array(x_corner_l)\n",
    "    #lefty = np.array(y_corner_l)\n",
    "\n",
    "#rightx = np.array([900 + (elem**2)*4e-4 + np.random.randint(-50, high=51) \n",
    "                                #for idx, elem in enumerate(yvals)])\n",
    "#rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    #rightx = np.array(x_corner_r)\n",
    "    #righty = np.array(y_corner_r)\n",
    "# Fit a second order polynomial to each fake lane line\n",
    "\n",
    "#########################################################\n",
    "    combined_binary = warped_img\n",
    "    \n",
    "    rightx = []\n",
    "    righty = []\n",
    "    leftx = []\n",
    "    lefty = []\n",
    "    \n",
    "    # Identify all non zero pixels in the image\n",
    "    x, y = np.nonzero(np.transpose(combined_binary)) \n",
    "\n",
    "    if Left.found == True: # Search for left lane pixels around previous polynomial\n",
    "        i = 720\n",
    "        j = 630\n",
    "        while j >= 0:\n",
    "            yval = np.mean([i,j])\n",
    "            xval = (np.mean(Left.fit0))*yval**2 + (np.mean(Left.fit1))*yval + (np.mean(Left.fit2))\n",
    "            x_idx = np.where((((xval - 25) < x)&(x < (xval + 25))&((y > j) & (y < i))))\n",
    "            x_window, y_window = x[x_idx], y[x_idx]\n",
    "            if np.sum(x_window) != 0:\n",
    "                np.append(leftx, x_window)\n",
    "                np.append(lefty, y_window)\n",
    "            i -= 90\n",
    "            j -= 90\n",
    "        if np.sum(leftx) == 0: \n",
    "            Left.found = False # If no lane pixels were detected then perform blind search\n",
    "        \n",
    "    if Right.found == True: # Search for right lane pixels around previous polynomial\n",
    "        i = 720\n",
    "        j = 630\n",
    "        while j >= 0:\n",
    "            yval = np.mean([i,j])\n",
    "            xval = (np.mean(Right.fit0))*yval**2 + (np.mean(Right.fit1))*yval + (np.mean(Right.fit2))\n",
    "            x_idx = np.where((((xval - 25) < x)&(x < (xval + 25))&((y > j) & (y < i))))\n",
    "            x_window, y_window = x[x_idx], y[x_idx]\n",
    "            if np.sum(x_window) != 0:\n",
    "                np.append(rightx, x_window)\n",
    "                np.append(righty, y_window)\n",
    "            \n",
    "            i -= 90\n",
    "            j -= 90\n",
    "        if np.sum(rightx) == 0:\n",
    "            Right.found = False # If no lane pixels were detected then perform blind search\n",
    "            \n",
    "    if Right.found == False: # Perform blind search for lane lines\n",
    "        i = 720\n",
    "        j = 630\n",
    "        while j >= 0:\n",
    "            histogram = np.sum(combined_binary[j:i,:], axis=0)\n",
    "            right_peak = np.argmax(histogram[640:]) + 640\n",
    "            x_idx = np.where((((right_peak - 25) < x)&(x < (right_peak + 25))&((y > j) & (y < i))))\n",
    "            x_window, y_window = x[x_idx], y[x_idx]\n",
    "            if np.sum(x_window) != 0:\n",
    "                rightx.extend(x_window.tolist())\n",
    "                righty.extend(y_window.tolist())\n",
    "            i -= 90\n",
    "            j -= 90\n",
    "    if not np.sum(righty) > 0:\n",
    "        righty = Right.Y\n",
    "        rightx = Right.X\n",
    "            \n",
    "    if Left.found == False:# Perform blind search for lane lines\n",
    "        i = 720\n",
    "        j = 630\n",
    "        while j >= 0:\n",
    "            histogram = np.sum(combined_binary[j:i,:], axis=0)\n",
    "            left_peak = np.argmax(histogram[:640])\n",
    "            x_idx = np.where((((left_peak - 25) < x)&(x < (left_peak + 25))&((y > j) & (y < i))))\n",
    "            x_window, y_window = x[x_idx], y[x_idx]\n",
    "            if np.sum(x_window) != 0:\n",
    "                leftx.extend(x_window.tolist())\n",
    "                lefty.extend(y_window.tolist())\n",
    "            i -= 90\n",
    "            j -= 90\n",
    "    if not np.sum(lefty) > 0:\n",
    "        lefty = Left.Y\n",
    "        leftx = Left.X\n",
    "        \n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "            \n",
    "    # Calculate left polynomial fit based on detected pixels\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    \n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    leftx_int = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    left_top = left_fit[0]*0**2 + left_fit[1]*0 + left_fit[2]\n",
    "    \n",
    "    # Average intercepts across 5 frames\n",
    "    Left.x_int.append(leftx_int)\n",
    "    Left.top.append(left_top)\n",
    "    leftx_int = np.mean(Left.x_int)\n",
    "    left_top = np.mean(Left.top)\n",
    "    Left.lastx_int = leftx_int\n",
    "    Left.last_top = left_top\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx, left_top)\n",
    "    lefty = np.append(lefty, 0)\n",
    "    lsort = np.argsort(lefty)\n",
    "    lefty = lefty[lsort]\n",
    "    leftx = leftx[lsort]\n",
    "    Left.X = leftx\n",
    "    Left.Y = lefty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across 5 frames\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    Left.fit0.append(left_fit[0])\n",
    "    Left.fit1.append(left_fit[1])\n",
    "    Left.fit2.append(left_fit[2])\n",
    "    left_fit = [np.mean(Left.fit0), \n",
    "                np.mean(Left.fit1), \n",
    "                np.mean(Left.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    Left.fitx = left_fitx\n",
    "    \n",
    "    # Calculate right polynomial fit based on detected pixels\n",
    "    right_fit = np.polyfit(np.int_(righty), np.int_(rightx), 2)\n",
    "\n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    rightx_int = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "    right_top = right_fit[0]*0**2 + right_fit[1]*0 + right_fit[2]\n",
    "    \n",
    "    # Average intercepts across 5 frames\n",
    "    Right.x_int.append(rightx_int)\n",
    "    rightx_int = np.mean(Right.x_int)\n",
    "    Right.top.append(right_top)\n",
    "    right_top = np.mean(Right.top)\n",
    "    Right.lastx_int = rightx_int\n",
    "    Right.last_top = right_top\n",
    "    rightx = np.append(rightx, rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx, right_top)\n",
    "    righty = np.append(righty, 0)\n",
    "    rsort = np.argsort(righty)\n",
    "    righty = righty[rsort]\n",
    "    rightx = rightx[rsort]\n",
    "    Right.X = rightx\n",
    "    Right.Y = righty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across 5 frames\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    Right.fit0.append(right_fit[0])\n",
    "    Right.fit1.append(right_fit[1])\n",
    "    Right.fit2.append(right_fit[2])\n",
    "    right_fit = [np.mean(Right.fit0), np.mean(Right.fit1), np.mean(Right.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    Right.fitx = right_fitx\n",
    "        \n",
    "    # Compute radius of curvature for each lane in meters\n",
    "    ym_per_pix = 30./720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*np.max(lefty) + left_fit_cr[1])**2)**1.5) \\\n",
    "                                 /np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*np.max(lefty) + right_fit_cr[1])**2)**1.5) \\\n",
    "                                    /np.absolute(2*right_fit_cr[0])\n",
    "        \n",
    "    # Only print the radius of curvature every 3 frames for improved readability\n",
    "    if Left.count % 3 == 0:\n",
    "        Left.radius = left_curverad\n",
    "        Right.radius = right_curverad\n",
    "        \n",
    "    # Calculate the vehicle position relative to the center of the lane\n",
    "    position = (rightx_int+leftx_int)/2\n",
    "    distance_from_center = abs((640 - position)*3.7/700) \n",
    "                \n",
    "    #Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([Left.fitx, Left.Y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, Right.Y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_(pts), (34,255,34))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.5, 0)\n",
    "    \n",
    "    \n",
    "    # Remember recent polynomial coefficients and intercepts\n",
    "    if len(Left.fit0) > 10:\n",
    "        Left.fit0 = Left.fit0[1:]\n",
    "    if len(Left.fit1) > 10:\n",
    "        Left.fit1 = Left.fit1[1:]\n",
    "    if len(Left.fit2) > 10:\n",
    "        Left.fit2 = Left.fit2[1:]\n",
    "    if len(Left.x_int) > 50:\n",
    "        Left.x_int = Left.x_int[1:]\n",
    "    if len(Left.top) > 50:\n",
    "        Left.top = Left.top[1:]\n",
    "    if len(Right.fit0) > 10:\n",
    "        Right.fit0 = Right.fit0[1:]\n",
    "    if len(Right.fit1) > 10:\n",
    "        Right.fit1 = Right.fit1[1:]\n",
    "    if len(Right.fit2) > 10:\n",
    "        Right.fit2 = Right.fit2[1:]\n",
    "    if len(Right.x_int) > 50:\n",
    "        Right.x_int = Right.x_int[1:]\n",
    "    if len(Right.top) > 50:\n",
    "        Right.top = Right.top[1:]\n",
    "        \n",
    "    # Print distance from center on video\n",
    "    if position > 640:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m left of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    else:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m right of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    # Print radius of curvature on video\n",
    "    cv2.putText(result, 'Radius of Curvature {}(m)'.format(int((Left.radius+Right.radius)/2)), (120,140),\n",
    "             fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    Left.count += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transform\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challange_output.mp4\n",
      "[MoviePy] Writing video challange_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [08:41<00:00,  2.03s/it]     | 1/251 [00:01<07:38,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challange_output.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Left.__init__(Left)\n",
    "Right.__init__(Right)\n",
    "video_output = 'challange_output.mp4'\n",
    "clip1 = VideoFileClip(\"challenge.mp4\")\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"360\" controls>\n",
       "  <source src=\"challange_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('challange_output.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-TensorFlow-Lab]",
   "language": "python",
   "name": "conda-env-CarND-TensorFlow-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
